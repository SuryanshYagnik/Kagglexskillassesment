{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xRUGM1PriIQf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import ElasticNet\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_data = pd.read_csv('/content/train.csv')\n",
        "test_data = pd.read_csv('/content/test.csv')\n"
      ],
      "metadata": {
        "id": "sRKnZYS-Yqlg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target variable\n",
        "X_train = train_data.drop(columns=['price', 'id'])\n",
        "y_train = train_data['price']\n",
        "X_test = test_data.drop(columns=['id'])"
      ],
      "metadata": {
        "id": "PVdF7mr6ZX4j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract numeric horsepower\n",
        "def extract_hp(engine_str):\n",
        "    match = re.search(r'(\\d+\\.\\d+|\\d+)HP', engine_str)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "# Apply function to extract horsepower\n",
        "if 'engine' in X_train.columns:\n",
        "    X_train['engine_hp'] = X_train['engine'].apply(extract_hp)\n",
        "if 'engine' in X_test.columns:\n",
        "    X_test['engine_hp'] = X_test['engine'].apply(extract_hp)"
      ],
      "metadata": {
        "id": "0ZTA7o99aMN-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the original 'engine' feature\n",
        "X_train.drop(columns=['engine'], inplace=True, errors='ignore')\n",
        "X_test.drop(columns=['engine'], inplace=True, errors='ignore')\n",
        "\n",
        "# Drop rows with NaN values in 'engine_hp' (if any)\n",
        "X_train = X_train.dropna(subset=['engine_hp'])\n",
        "y_train = y_train.loc[X_train.index]"
      ],
      "metadata": {
        "id": "9hDdfTWjaQF8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in 'engine_hp' with the mean of the column\n",
        "X_train['engine_hp'].fillna(X_train['engine_hp'].mean(), inplace=True)\n",
        "X_test['engine_hp'].fillna(X_test['engine_hp'].mean(), inplace=True)\n",
        "\n",
        "# Define numerical and categorical features\n",
        "numeric_features = ['model_year', 'milage', 'engine_hp']\n",
        "categorical_features = ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
        "\n",
        "# Create transformers for numeric and categorical data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformers into a single preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline that combines preprocessing and the ElasticNet model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', ElasticNet(random_state=42))\n",
        "])\n",
        "\n",
        "# Define hyperparameter grid for tuning\n",
        "param_grid = {\n",
        "    'regressor__alpha': [0.1, 1.0, 10.0],\n",
        "    'regressor__l1_ratio': [0.1, 0.5, 0.9]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Train the model using GridSearchCV\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"GridSearchCV training time: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = best_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDMz2-G9rzYH",
        "outputId": "980b446f-53a7-4837-99c3-ed6aae7c1478"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV training time: 169.02 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we don't have true price labels for the test set, we'll calculate RMSE on a portion of the training data held out as validation set\n",
        "# Split the training data into a smaller training set and a validation set\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the best model on the split training data\n",
        "best_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "print(f\"Validation RMSE: {rmse:.2f}\")\n",
        "\n",
        "# Save the predictions to a CSV file in the format [id, price]\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'price': y_test_pred\n",
        "})\n",
        "submission.to_csv('/content/predicted_prices_Elasticnet.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xm2Y4f5hTJR",
        "outputId": "2bf9c993-c927-4075-f824-b422a6cbf4ee"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE: 66195.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of ID column in test_data:\", len(test_data['id']))\n",
        "print(\"Length of predicted prices array:\", len(y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hTZ5jqCuzaE",
        "outputId": "8f0cd14f-f731-45f9-865b-13436e72d632"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of ID column in test_data: 36183\n",
            "Length of predicted prices array: 33577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance\n",
        "importances = best_model.named_steps['regressor'].feature_importances_\n",
        "feature_names = numeric_features + list(best_model.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features))\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
        "\n",
        "print(feature_importances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "gmX9EV7dzuNa",
        "outputId": "df1e7b95-b617-4f8b-c5c8-fd9726d9da86"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ElasticNet' object has no attribute 'feature_importances_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-94cf18c7c573>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'regressor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create a DataFrame for visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ElasticNet' object has no attribute 'feature_importances_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDfcRY6hi4CC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}