{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xRUGM1PriIQf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import ElasticNet\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_data = pd.read_csv('/content/train.csv')\n",
        "test_data = pd.read_csv('/content/test.csv')\n"
      ],
      "metadata": {
        "id": "sRKnZYS-Yqlg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target variable\n",
        "X_train = train_data.drop(columns=['price', 'id'])\n",
        "y_train = train_data['price']\n",
        "X_test = test_data.drop(columns=['id'])"
      ],
      "metadata": {
        "id": "PVdF7mr6ZX4j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract numeric horsepower\n",
        "def extract_hp(engine_str):\n",
        "    match = re.search(r'(\\d+\\.\\d+|\\d+)HP', engine_str)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "# Apply function to extract horsepower\n",
        "if 'engine' in X_train.columns:\n",
        "    X_train['engine_hp'] = X_train['engine'].apply(extract_hp)\n",
        "if 'engine' in X_test.columns:\n",
        "    X_test['engine_hp'] = X_test['engine'].apply(extract_hp)"
      ],
      "metadata": {
        "id": "0ZTA7o99aMN-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the original 'engine' feature\n",
        "X_train.drop(columns=['engine'], inplace=True, errors='ignore')\n",
        "X_test.drop(columns=['engine'], inplace=True, errors='ignore')\n",
        "\n",
        "# Drop rows with NaN values in 'engine_hp' (if any)\n",
        "X_train = X_train.dropna(subset=['engine_hp'])\n",
        "y_train = y_train.loc[X_train.index]"
      ],
      "metadata": {
        "id": "9hDdfTWjaQF8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define numerical and categorical features\n",
        "numeric_features = ['model_year', 'milage', 'engine_hp']\n",
        "categorical_features = ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
        "\n",
        "# Create transformers for numeric and categorical data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformers into a single preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline that combines preprocessing and the LightGBM model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', lgb.LGBMRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# Define hyperparameter grid for tuning\n",
        "param_grid = {\n",
        "    'regressor__n_estimators': [100, 200, 300],\n",
        "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'regressor__num_leaves': [31, 50, 100]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Train the model using GridSearchCV\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"GridSearchCV training time: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDMz2-G9rzYH",
        "outputId": "9ee46254-e9d9-4604-d55c-258a62bf5c95"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009107 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1983\n",
            "[LightGBM] [Info] Number of data points in the train set: 50216, number of used features: 733\n",
            "[LightGBM] [Info] Start training from score 37478.310419\n",
            "GridSearchCV training time: 217.72 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we don't have true price labels for the test set, we'll calculate RMSE on a portion of the training data held out as validation set\n",
        "# Split the training data into a smaller training set and a validation set\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the best model on the split training data\n",
        "best_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "print(f\"Validation RMSE: {rmse:.2f}\")\n",
        "\n",
        "# Save the predictions to a CSV file in the format [id, price]\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'price': y_test_pred\n",
        "})\n",
        "submission.to_csv('/content/predicted_prices.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xm2Y4f5hTJR",
        "outputId": "fe73e0d0-a54d-4fe1-cdec-59a54dc6f71c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127616 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1750\n",
            "[LightGBM] [Info] Number of data points in the train set: 40172, number of used features: 617\n",
            "[LightGBM] [Info] Start training from score 37318.183635\n",
            "Validation RMSE: 66131.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of ID column in test_data:\", len(test_data['id']))\n",
        "print(\"Length of predicted prices array:\", len(y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hTZ5jqCuzaE",
        "outputId": "8f0cd14f-f731-45f9-865b-13436e72d632"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of ID column in test_data: 36183\n",
            "Length of predicted prices array: 33577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance\n",
        "importances = best_model.named_steps['regressor'].feature_importances_\n",
        "feature_names = numeric_features + list(best_model.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features))\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
        "\n",
        "print(feature_importances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmX9EV7dzuNa",
        "outputId": "ccee17f8-5933-4d89-a12b-af1555330647"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              feature  importance\n",
            "1                              milage        1992\n",
            "0                          model_year        1482\n",
            "2                           engine_hp        1421\n",
            "43                      brand_Porsche         296\n",
            "1557                   model_Tahoe LT         252\n",
            "...                               ...         ...\n",
            "639         model_Expedition Platinum           0\n",
            "638          model_Expedition Max XLT           0\n",
            "637      model_Expedition Max Limited           0\n",
            "636   model_Expedition Max King Ranch           0\n",
            "1867                  clean_title_Yes           0\n",
            "\n",
            "[1868 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDfcRY6hi4CC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}