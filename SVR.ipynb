{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRUGM1PriIQf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRKnZYS-Yqlg"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "train_data = pd.read_csv('/content/train.csv')\n",
        "test_data = pd.read_csv('/content/test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh1sycW-xJ0i"
      },
      "outputs": [],
      "source": [
        "# Add a time-related feature, 'age' of the vehicle\n",
        "current_year = 2024  # Assuming the current year is 2024\n",
        "train_data['age'] = current_year - train_data['model_year']\n",
        "test_data['age'] = current_year - test_data['model_year']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVdF7mr6ZX4j"
      },
      "outputs": [],
      "source": [
        "# Features and target variable\n",
        "X_train = train_data.drop(columns=['price', 'id'])\n",
        "y_train = train_data['price']\n",
        "X_test = test_data.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZTA7o99aMN-"
      },
      "outputs": [],
      "source": [
        "# Function to extract numeric horsepower\n",
        "def extract_hp(engine_str):\n",
        "    match = re.search(r'(\\d+\\.\\d+|\\d+)HP', engine_str)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "# Apply function to extract horsepower\n",
        "if 'engine' in X_train.columns:\n",
        "    X_train['engine_hp'] = X_train['engine'].apply(extract_hp)\n",
        "if 'engine' in X_test.columns:\n",
        "    X_test['engine_hp'] = X_test['engine'].apply(extract_hp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hDdfTWjaQF8"
      },
      "outputs": [],
      "source": [
        "# Drop the original 'engine' feature\n",
        "X_train.drop(columns=['engine'], inplace=True, errors='ignore')\n",
        "X_test.drop(columns=['engine'], inplace=True, errors='ignore')\n",
        "\n",
        "# Drop rows with NaN values in 'engine_hp' (if any)\n",
        "X_train = X_train.dropna(subset=['engine_hp'])\n",
        "y_train = y_train.loc[X_train.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XDMz2-G9rzYH"
      },
      "outputs": [],
      "source": [
        "# Define numerical and categorical features\n",
        "numeric_features = ['model_year', 'milage', 'engine_hp', 'age']\n",
        "categorical_features = ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
        "\n",
        "# Create transformers for numeric and categorical data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformers into a single preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Preprocess training and testing data\n",
        "X_train_processed = preprocessor.fit_transform(X_train).toarray()  # Convert to dense array\n",
        "X_test_processed = preprocessor.transform(X_test).toarray()        # Convert to dense array\n",
        "\n",
        "# Train the SVR model\n",
        "svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
        "svr.fit(X_train_processed, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = svr.predict(X_test_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ7KkvSax-HL"
      },
      "outputs": [],
      "source": [
        "# Ensure all IDs have predictions by creating a DataFrame with all IDs\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'price': y_test_pred.flatten()\n",
        "})\n",
        "\n",
        "# Save the predictions to a CSV file in the format [id, price]\n",
        "submission.to_csv('/content/SVM_prices.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xm2Y4f5hTJR",
        "outputId": "2bf9c993-c927-4075-f824-b422a6cbf4ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation RMSE: 66195.88\n"
          ]
        }
      ],
      "source": [
        "# Since we don't have true price labels for the test set, we'll calculate RMSE on a portion of the training data held out as validation set\n",
        "# Split the training data into a smaller training set and a validation set\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the best model on the split training data\n",
        "best_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "print(f\"Validation RMSE: {rmse:.2f}\")\n",
        "\n",
        "# Save the predictions to a CSV file in the format [id, price]\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'price': y_test_pred\n",
        "})\n",
        "submission.to_csv('/content/predicted_prices_Elasticnet.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDfcRY6hi4CC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}